{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler #scalers \n",
    "from sklearn.metrics import r2_score, mean_absolute_error #score used for regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor #Random Forest Model\n",
    "from sklearn.ensemble import GradientBoostingRegressor #Gradient Boost Model\n",
    "from sklearn.tree import DecisionTreeRegressor #Decision Tree Model\n",
    "from xgboost import XGBRegressor #XGBoost Model\n",
    "from lightgbm import LGBMRegressor #LightGBM Model\n",
    "from sklearn.model_selection import GridSearchCV #Grid Search Cross Validation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data scaling and splitting 'datetime' into 'date' and 'time', excluding delimeteres\n",
    "\n",
    "data=pd.read_csv(r'C:/Users/daima/OneDrive/Documenti/GDP/ML/src/train.csv')\n",
    "new= data[\"detection_time\"].str.split(\" \", n = 0, expand = True)\n",
    "data['date'] = new[0]\n",
    "data['time'] = new[1]\n",
    "data['time'] = pd.Series((data['time']).astype(str).str.replace(':', '', regex=False))\n",
    "data['date'] = pd.Series((data['date']).astype(str).str.replace('-', '', regex=False))\n",
    "data['time'] = data['time'].astype(int)\n",
    "data['date'] = data['date'].astype(int)\n",
    "data = data.drop([\"detection_time\",\"tracked_point_id\"], axis=1)\n",
    "data['holiday'] = data.holiday.astype(int)\n",
    "transformers = [\n",
    "        ['one_hot', OneHotEncoder(), ['season','weather', 'time']],\n",
    "        ['scaler', StandardScaler(), ['weather_index','event_index','attractions_index','time_index', 'date']],\n",
    "]\n",
    "ct = ColumnTransformer(transformers, remainder=\"passthrough\")\n",
    "X = ct.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check NaN values on people_concentration column\n",
    "\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342144\n",
      "341297\n"
     ]
    }
   ],
   "source": [
    "#detecting and deleting rows with outliers in any column\n",
    "\n",
    "#dataset length before checking outliers\n",
    "print(len(data.index))\n",
    "data = data[(np.abs(stats.zscore(data['people_concentration'])) < 3)]\n",
    "\n",
    "#dataset length after checking and removing outliers\n",
    "print(len(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56871\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>weather</th>\n",
       "      <th>events</th>\n",
       "      <th>attractions</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weather_index</th>\n",
       "      <th>attractions_index</th>\n",
       "      <th>event_index</th>\n",
       "      <th>time_index</th>\n",
       "      <th>people_concentration</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>20180101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20180101</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20180101</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>20180101</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20180101</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>20180107</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20180107</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>20180107</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20180107</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20180107</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season  weather  events  attractions  holiday  weather_index  \\\n",
       "0          0        0       0            0        1              3   \n",
       "6          0        0       0            0        1              3   \n",
       "12         0        0       0            0        1              3   \n",
       "18         0        0       0            0        1              3   \n",
       "24         0        0       0            0        1              3   \n",
       "...      ...      ...     ...          ...      ...            ...   \n",
       "1794       0        0       0            0        0              3   \n",
       "1800       0        0       0            0        0              3   \n",
       "1806       0        0       0            0        0              3   \n",
       "1812       0        0       0            0        0              3   \n",
       "1818       0        0       0            0        0              3   \n",
       "\n",
       "      attractions_index  event_index  time_index  people_concentration  \\\n",
       "0                     3            4           2                    17   \n",
       "6                     3            4           2                    16   \n",
       "12                    3            4           2                    16   \n",
       "18                    3            4           2                    17   \n",
       "24                    3            4           2                    13   \n",
       "...                 ...          ...         ...                   ...   \n",
       "1794                  3            4           2                     5   \n",
       "1800                  3            4           2                     6   \n",
       "1806                  3            4           2                     7   \n",
       "1812                  3            4           2                    13   \n",
       "1818                  3            4           2                    13   \n",
       "\n",
       "          date  time  \n",
       "0     20180101     0  \n",
       "6     20180101    30  \n",
       "12    20180101   100  \n",
       "18    20180101   130  \n",
       "24    20180101   200  \n",
       "...        ...   ...  \n",
       "1794  20180107   530  \n",
       "1800  20180107   600  \n",
       "1806  20180107   630  \n",
       "1812  20180107   700  \n",
       "1818  20180107   730  \n",
       "\n",
       "[300 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering dataset\n",
    "\n",
    "time_array = [0, 30, 100, 130, 200, 230, 300, 330, 400, 430, 500, 530,\n",
    "             600, 630, 700, 730, 800, 830, 900, 930, 1000, 1030, 1100,\n",
    "             1130, 1200, 1230, 1300, 1330, 1400, 1430, 1500, 1530,\n",
    "             1600, 1630, 1700, 1730, 1800, 1830, 1900, 1930, 2000,\n",
    "             2030, 2100, 2130, 2200, 2230, 2300, 2330]\n",
    "data_filtered = data.loc[data['time'].isin(time_array)]\n",
    "data_1 = len(data_filtered.index)\n",
    "print(data_1)\n",
    "data_filtered.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into training and testing\n",
    "\n",
    "X = data_filtered.drop([\"people_concentration\"], axis=1)  # features\n",
    "y = data_filtered[\"people_concentration\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed: 124.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 8, 'n_estimators': 150, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "#Random forest parameters dictionary Grid Search CV\n",
    "parameters_rf = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, None],\n",
    " 'max_features': ['auto', 'sqrt', 'log2'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [10, 50, 100],\n",
    " 'random_state': [None, 1]\n",
    "}\n",
    "\n",
    "#Decision Tree parameters dictionary Grid Search CV\n",
    "parameters_dt = {'max_depth': [10, 20, 30, 50, None],\n",
    "    'min_samples_split': [2, 5, 10, 50, 500],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'random_state': [None, 1],\n",
    "    'min_samples_leaf': [1, 2, 4, 10, 50],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.2, 0.5, 0.75],\n",
    "    'max_features': ['sqrt', 'log2', 'auto']\n",
    "}\n",
    "\n",
    "#XGBoost parameters dictionary Grid Search CV\n",
    "parameters_xgb = {\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "    'learning_rate': [0.01, 0.1, 0.25],\n",
    "    'max_depth': [1, 2, 5, 10, None],\n",
    "    'gamma': [0.1, 0.5, 0.9],\n",
    "    'subsample': [0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "#LightGBM parameters dictionary Grid Search CV\n",
    "parameters_lgbm = {\n",
    "    'learning_rate': [0.01, 0.1, 0.25],\n",
    "    'max_depth': [5, 8, 10, None],\n",
    "    'boosting_type' : ['gbdt', 'dart', 'rf', 'goss'],\n",
    "    'num_leaves': [10, 20, 30],\n",
    "    'subsample': [0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "#Decision Tree parameters dictionary Grid Search CV\n",
    "parameters_gbt = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.25],\n",
    "    'loss': ['ls', 'lad', 'quantile'],\n",
    "    'max_depth': [8, 16, 32, None],\n",
    "    'subsample': [0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "#Grid Search CV\n",
    "gbt_model = GradientBoostingRegressor()\n",
    "CV_gbt = GridSearchCV(estimator = gbt_model, param_grid = parameters_gbt, verbose=1, n_jobs=-1)\n",
    "CV_gbt.fit(X_train, y_train)\n",
    "\n",
    "#Best parameteres from Grid Search CV\n",
    "print(CV_gbt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score: 0.7348167796253234\n"
     ]
    }
   ],
   "source": [
    "#Testing Random Forest parameters\n",
    "\n",
    "rf_model = RandomForestRegressor(bootstrap = True, max_depth = 10, max_features = 'sqrt', min_samples_leaf = 4, min_samples_split = 5, n_estimators = 100, random_state = None)\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Random Forest score: \" + str(r2_score(y_test, rf_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score: 0.7444337069130583\n"
     ]
    }
   ],
   "source": [
    "#Testing Decision Tree parameters\n",
    "\n",
    "dt_model = DecisionTreeRegressor(max_depth = 20, min_samples_leaf = 10, min_samples_split = 500, min_weight_fraction_leaf = 0.0, random_state = None, splitter = 'random', max_features = 'auto')\n",
    "dt_model.fit(X_train, y_train)\n",
    "print(\"Decision Tree score: \" + str(r2_score(y_test, dt_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost score: 0.7404509996951192\n"
     ]
    }
   ],
   "source": [
    "#Testing XGBoost parameters\n",
    "\n",
    "xgb_model = XGBRegressor(booster='dart', gamma= 0.1, learning_rate= 0.1, max_depth= 2, subsample= 0.2)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"XGBoost score: \" + str(r2_score(y_test, xgb_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM score: 0.7422874141579745\n"
     ]
    }
   ],
   "source": [
    "#Testing LightGBM parameters\n",
    "\n",
    "lgbm_model = LGBMRegressor(boosting_type='gbdt', learning_rate=0.1, max_depth= 5, num_leaves= 10, subsample= 1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "print(\"Light GBM score: \" + str(r2_score(y_test, lgbm_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost score: 0.7435714107043585\n"
     ]
    }
   ],
   "source": [
    "#Testing Gradient Boost parameters\n",
    "\n",
    "gb_model = GradientBoostingRegressor(learning_rate= 0.01, loss= 'ls', max_depth= 8, n_estimators= 150, subsample= 0.2)\n",
    "gb_model.fit(X_train, y_train)\n",
    "print(\"Gradient Boost score: \" + str(r2_score(y_test, gb_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Risultati score di regressione in seguito all'utilizzo di Grid Search Cross Validation sui modelli individuati, allenati tutti\n",
    "#con i best_params_ individuati\n",
    "\n",
    "#Random Forest score: 0.7348167796253234\n",
    "#Decision Tree score: 0.7444337069130583\n",
    "#XGBoost score: 0.7404509996951192\n",
    "#Light GBM score: 0.7422874141579745\n",
    "#Gradient Boost score: 0.7435714107043585\n",
    "\n",
    "#In seguito ai test eseguiti con i modelli di default e con i best_params_ prodotti dalle operazioni di Grid Search Cross Validation\n",
    "#sui parametri dei vari modelli, si è deciso di adottare in definitiva i modelli Random Forest, Decision Tree e Gradient Boost.\n",
    "#Il gruppo ha deciso di scartare LightGBM e XGBoost, in quanto più onerosi dal punto di vista computazionale con risultati che non\n",
    "#ne giustificassero l'utilizzo in relazione ai costi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
